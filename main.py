"""ImageSuperResolution.ipynb

Automatically generated by Colaboratory.

Original file is located at 
    https://colab.research.google.com/drive/1H4vaXfWdRr35i0d6IZtoWBuOGGjXBQsY?usp=sharing
"""

from tensorflow.keras.layers import add, Conv2D, UpSampling2D, Dense, MaxPooling2D, Dropout, Conv2DTranspose, Input
from tensorflow.keras.models import Model
from tensorflow.keras import regularizers
import matplotlib.pyplot as plt

import os
import re
from skimage.transform import resize, rescale
from matplotlib import pyplot
import numpy as np

"""**ENCODER**"""

input_img = Input(shape=(64, 64, 3))

l1 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)
l2 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)
l3 = MaxPooling2D(padding='same')(l2)
l3 = Dropout(0.3)(l3)
l4 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)
l5 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)
l6 = MaxPooling2D(padding='same')(l5)
l7 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)
encoder = Model(input_img, l7)

encoder.summary()

"""**DECODER**"""

l1 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)
l2 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)
l3 = MaxPooling2D(padding='same')(l2)
l3 = Dropout(0.3)(l3)
l4 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)
l5 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)
l6 = MaxPooling2D(padding='same')(l5)
l7 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)

l8 = UpSampling2D()(l7)
l9 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l8)
l10 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)

l11 = add([l5, l10])
l12 = UpSampling2D()(l11)
l13 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l12)
l14 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)
l15 = add([l14, l2])
decoded = Conv2D(3, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l15)

autoencoder = Model(input_img, decoded)
autoencoder_hfenn = Model(input_img, decoded)

autoencoder.summary()
autoencoder.compile(optimizer="Adam", loss="mse")


def train_batches(just_load_dataset=False):
    batches = 64  # Number of images to have at the same time in a batch

    batch = 0  # Number if images in the current batch (grows over time and then resets for each batch)
    batch_nb = 0  # Batch current index

    max_batches = -1  # If you want to train only on a limited number of images to finish the training even faster.

    ep = 4  # Number of epochs

    images = []
    x_train_n = []
    x_train_down = []

    x_train_n2 = []  # Resulting high res dataset
    x_train_down2 = []  # Resulting low res dataset

    for root, dirnames, filenames in os.walk("data/DIV2K_train_HR"):
        for filename in filenames:
            if re.search("\.(jpg|jpeg|JPEG|png|bmp|tiff)$", filename):
                if batch_nb == max_batches:  # If we limit the number of batches, just return earlier
                    return x_train_n2, x_train_down2
                filepath = os.path.join(root, filename)
                image = pyplot.imread(filepath)
                if len(image.shape) > 2:

                    image_resized = resize(image, (64, 64))  # Resize the image so that every image is the same size
                    x_train_n.append(image_resized)  # Add this image to the high res dataset
                    x_train_down.append(rescale(rescale(image_resized, 0.5, multichannel=True),
                                                2.0,
                                                multichannel=True))  # Rescale it 0.5x and 2x so that it is a low res image but still has 64x64 resolution
                    batch += 1
                    if batch == batches:
                        batch_nb += 1

                        x_train_n2 = np.array(x_train_n)
                        x_train_down2 = np.array(x_train_down)

                        if just_load_dataset:
                            return x_train_n2, x_train_down2

                        print('Training batch', batch_nb, '(', batches, ')')

                        autoencoder.fit(x_train_down2, x_train_n2,
                                        epochs=ep,
                                        batch_size=10,
                                        shuffle=True,
                                        validation_split=0.15)

                        x_train_n = []
                        x_train_down = []

                        batch = 0

    return x_train_n2, x_train_down2


x_train_n, x_train_down = train_batches(just_load_dataset=False)

autoencoder.save_weights("sr.img_net.mse.final_model5.no_patch.weights.best.hdf5")

# encoder.load_weights('encoder_weights.hdf5')
#
# encoded_imgs = encoder.predict(x_train_down)

sr1 = np.clip(autoencoder.predict(x_train_down), 0.0, 1.0)

image_index = np.random.randint(0, 64)

plt.figure(figsize=(128, 128))
i = 1
ax = plt.subplot(10, 10, i)
plt.imshow(x_train_down[image_index])
i += 1
ax = plt.subplot(10, 10, i)
plt.imshow(x_train_down[image_index], interpolation="bicubic")
# i += 1
# ax = plt.subplot(10, 10, i)
# plt.imshow(encoded_imgs[image_index].reshape((64 * 64, 64)))
i += 1
ax = plt.subplot(10, 10, i)
plt.imshow(sr1[image_index])
i += 1
ax = plt.subplot(10, 10, i)
plt.imshow(x_train_n[image_index])
plt.show()
